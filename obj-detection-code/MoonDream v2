import cv2
import time
import numpy as np
import pyrealsense2 as rs
from PIL import Image
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer


# --- Constants ---
W = 640
H = 480
# --- PERFORMANCE OPTIMIZATION ---
# We will only run the VLM once every 2 seconds to prevent system overload.
UPDATE_INTERVAL = 2.0  # seconds


# --- Helper Function for Displaying Text ---
def draw_text_on_image(img, text, position=(20, 30), font_scale=0.7, thickness=2):
   """Draws multi-line text with a semi-transparent background on an image."""
   font = cv2.FONT_HERSHEY_SIMPLEX
   text_color = (255, 255, 255) # White
   bg_color = (0, 0, 0) # Black
  
   lines = text.split('\n')
   max_width = 0
   total_height = 0
   line_heights = []


   for line in lines:
       (w, h), _ = cv2.getTextSize(line, font, font_scale, thickness)
       max_width = max(max_width, w)
       total_height += h + 10
       line_heights.append(h + 10)


   x, y = position
  
   # Create a semi-transparent overlay for the background
   overlay = img.copy()
   cv2.rectangle(overlay, (x - 10, y - 25), (x + max_width + 10, y + total_height - 20), bg_color, -1)
   alpha = 0.6
   cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0, img)


   # Draw the text on top of the overlay
   current_y = y
   for i, line in enumerate(lines):
       cv2.putText(img, line, (x, current_y), font, font_scale, text_color, thickness, cv2.LINE_AA)
       current_y += line_heights[i]


# --- MoonDream Model Loading ---
print("Loading MoonDream model...")
model_id = "vikhyatk/moondream2"
tokenizer = AutoTokenizer.from_pretrained(model_id)
moondream_model = AutoModelForCausalLM.from_pretrained(
   model_id, trust_remote_code=True,
   torch_dtype=torch.float16, revision="2024-05-20"
).to("cuda")
print("MoonDream model loaded successfully.")


# --- RealSense Pipeline Setup ---
print("Initializing RealSense camera...")
pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.color, W, H, rs.format.bgr8, 30)
pipeline.start(config)
print("RealSense camera started.")


prompt = "Describe the main object in the center of the image."


# --- Variables for Timed Inference ---
last_update_time = 0
description = "Analyzing..." # Initial text to display


print("Starting camera feed...")
try:
   while True:
       # --- Get camera frames continuously for a smooth video feed ---
       frames = pipeline.wait_for_frames()
       color_frame = frames.get_color_frame()
       if not color_frame:
           continue


       color_image = np.asanyarray(color_frame.get_data())
      
       # --- Timed Inference Block ---
       current_time = time.time()
       if current_time - last_update_time > UPDATE_INTERVAL:
           last_update_time = current_time
          
           # This heavy block of code only runs every UPDATE_INTERVAL seconds
           print("Running MoonDream inference...")
           pil_image = Image.fromarray(cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB))
          
           with torch.no_grad():
               enc_image = moondream_model.encode_image(pil_image)
               # Generate a new description
               description = moondream_model.answer_question(
                   image_embeds=enc_image,
                   question=prompt,
                   tokenizer=tokenizer
               )
           print(f"New Description: {description}")


       # --- Display the results on EVERY frame for a smooth experience ---
       # We always draw, but the 'description' text only changes periodically.
       annotated_frame = color_image.copy()
       draw_text_on_image(annotated_frame, description)
       cv2.imshow("MoonDream Description", annotated_frame)


       if cv2.waitKey(1) & 0xFF == ord('q'):
           break
finally:
   print("Stopping camera and closing windows.")
   pipeline.stop()
   cv2.destroyAllWindows()
